Our second idea aims at performing context-specific text generation. Here our
goal is to learn a language model that's conditioned on a given domain. We
plan on using reddit data which is split into many subcommunities, and
classification data such as the yelp review dataset. Our MVP goal
is to implement the model from Low-Rank RNN Adaptation for Context-Aware
Language Modeling (Jaech and Ostendorf) to train a language model that shares
parameters between domans, while learning domain-specific embeddings that
adapt the RNN parameters. We plan on performing analytical experimemts such as
interpolating between diffent communties' embeddings to analyze the properties
of our model. Our stretch goal for this project idea is to also apply the methods
of Bowman et al. in Generating Sentences from a Continuous Space, only now
sampling from the space of domain embeddings.
